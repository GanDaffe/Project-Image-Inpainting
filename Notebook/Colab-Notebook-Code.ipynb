{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7079,
     "status": "ok",
     "timestamp": 1736614783387,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "plZLPk4KT58Y",
    "outputId": "6ec9e442-cfd9-4732-9b5b-77b63e458346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opendatasets\n",
      "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.67.1)\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.17)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.8)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
      "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: opendatasets\n",
      "Successfully installed opendatasets-0.1.22\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22505,
     "status": "ok",
     "timestamp": 1736614805890,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "I7gHfRctPdc4",
    "outputId": "fe93c241-ce9a-45b7-c374-25ef8d9a7f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: hoangquangduy\n",
      "Your Kaggle Key: ··········\n",
      "Dataset URL: https://www.kaggle.com/datasets/prasunroy/natural-images\n",
      "Downloading natural-images.zip to ./natural-images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342M/342M [00:04<00:00, 76.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./natural-images\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "od.download('www.kaggle.com/datasets/prasunroy/natural-images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 15484,
     "status": "ok",
     "timestamp": 1736615941724,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "vJbC8ff14vA7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import save_image\n",
    "from math import log2, sqrt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736615941725,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "d-HyziBc4roX"
   },
   "outputs": [],
   "source": [
    "DATASET = '/content/natural-images/natural_images'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 120\n",
    "LR = 2e-4\n",
    "SEED = 42\n",
    "IM_SIZE = 128\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1736615941726,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "p-cnlgd-6Yic"
   },
   "outputs": [],
   "source": [
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "\n",
    "    return ssim_map.mean()\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "\n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736615941726,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "u_ixohgp498q"
   },
   "outputs": [],
   "source": [
    "class MaskMaker():\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "\n",
    "        self.action_list = [[1, 0], [-1, 0], [0, 1], [0, -1], [1, 1], [-1, -1]]\n",
    "\n",
    "    def pos_clip(self, pix, img_size):\n",
    "        if pix < 0:\n",
    "            return 0\n",
    "        elif pix > img_size - 1:\n",
    "            return img_size - 1\n",
    "\n",
    "        return pix\n",
    "\n",
    "    def random_walk(self, canvas, ini_x, ini_y, length):\n",
    "        x, y = ini_x, ini_y\n",
    "        img_size = canvas.shape\n",
    "\n",
    "        for i in range(length):\n",
    "            r = random.randint(0, len(self.action_list) - 1)\n",
    "\n",
    "            x += self.action_list[r][0]\n",
    "            y += self.action_list[r][1]\n",
    "\n",
    "            x = self.pos_clip(x, img_size[0])\n",
    "            y = self.pos_clip(y, img_size[1])\n",
    "            canvas[x, y] = 0\n",
    "\n",
    "        return canvas\n",
    "\n",
    "    def forward(self):\n",
    "        image_size = self.shape\n",
    "\n",
    "        canvas = np.ones((image_size[0],image_size[1])).astype(\"i\")\n",
    "        ini_x = random.randint(0, image_size[0]-1)\n",
    "        ini_y = random.randint(0, image_size[1]-1)\n",
    "\n",
    "        mask = self.random_walk(canvas,ini_x,ini_y,int(image_size[0] * image_size[1]))\n",
    "\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1736616128451,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "TcJqwhEnCznw"
   },
   "outputs": [],
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=3, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736615941726,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "yqQY3kqxChmv"
   },
   "outputs": [],
   "source": [
    "def get_loader(train_ratio=0.8):\n",
    "    transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((IM_SIZE, IM_SIZE)),\n",
    "                # transforms.Normalize(\n",
    "                #     [0.5 for _ in range(3 )], [0.5 for _ in range(3)]\n",
    "                # ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    dataset = datasets.ImageFolder(\n",
    "        root=DATASET,\n",
    "        transform=transform,\n",
    "    )\n",
    "\n",
    "    datasize = len(dataset)\n",
    "    trainsize = int(train_ratio * datasize)\n",
    "    testsize = datasize - trainsize\n",
    "\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        dataset, [trainsize, testsize]\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736615941726,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "wUymmRO65BWm"
   },
   "outputs": [],
   "source": [
    "def make_input(img_batch):\n",
    "    preproc = MaskMaker((IM_SIZE, IM_SIZE))\n",
    "    newinput = []\n",
    "\n",
    "    for i in range(img_batch.shape[0]):\n",
    "        img = img_batch[i]\n",
    "\n",
    "        mask = preproc.forward()\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0).to(device)\n",
    "\n",
    "        new_img = mask * img\n",
    "        # new_img = new_img.to(torch.float32)\n",
    "\n",
    "        newinput.append(new_img)\n",
    "\n",
    "    newinput = torch.stack(newinput)\n",
    "    return newinput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736615941726,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "_WdxPvm0IiGi"
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1736615942057,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "aPvIuutVRWxV"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "def training(model,\n",
    "             train_loader,\n",
    "             optimizer,\n",
    "             loss_fn,\n",
    "             ssim):\n",
    "    loss_ = []\n",
    "    ssim_capture = []\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        model.train()\n",
    "\n",
    "        loss_sum = 0.0  # Initialize loss sum for this epoch\n",
    "        ssim_avg = 0.0\n",
    "        for batch_idx, (images, _) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            inp = make_input(images).to(device)\n",
    "\n",
    "            pred = model(inp)\n",
    "\n",
    "            loss = loss_fn(pred, images)\n",
    "            ssim_ = ssim(pred, images)\n",
    "\n",
    "            loss += (1 - ssim_)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            ssim_avg += ssim_.item()\n",
    "\n",
    "\n",
    "        loss_.append(loss_sum / len(train_loader))\n",
    "        ssim_capture.append(ssim_avg / len(train_loader))\n",
    "        print(f'Epoch {epoch + 1}/{EPOCHS}, Loss: {loss_sum / len(train_loader)}, SSIM: {ssim_avg / len(train_loader)}')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Vẽ loss trên ax[0]\n",
    "    ax[0].plot(list(range(70)), loss_[:70])\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Value')\n",
    "\n",
    "    ax[1].plot(list(range(70)), ssim_capture[:70])\n",
    "    ax[1].set_title('Chỉ số SSIM')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Value')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return loss_, ssim_capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736615942058,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "nDVDv7L4UasP"
   },
   "outputs": [],
   "source": [
    "def sharpen(image):\n",
    "    image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    kernel_size = (31, 31)  # Kích thước kernel\n",
    "    sigma = 5.0\n",
    "    blurred_image = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "\n",
    "    sharpened_image_unsharp = cv2.addWeighted(image, 1.5, blurred_image, -0.5, 0)\n",
    "\n",
    "    kernel_sharpening = np.array([[0, -0.5, 0],\n",
    "                               [-0.5, 3, -0.5],\n",
    "                               [0, -0.5, 0]])\n",
    "    sharpened_image_kernel = cv2.filter2D(sharpened_image_unsharp, -1, kernel_sharpening)\n",
    "\n",
    "    return sharpened_image_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736615942058,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "X7BBqpkDhutI"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_result(in_imgs, pred_img, true_img):\n",
    "    num = in_imgs.shape[0]\n",
    "    if num <= 1:\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(9, 2 * num))\n",
    "\n",
    "        img = in_imgs[0].cpu()\n",
    "        img = img * 255\n",
    "        img = img.int().permute(1, 2, 0).numpy()\n",
    "        axs[0].imshow(img)\n",
    "        axs[0].axis('off')\n",
    "\n",
    "        img = pred_img[0].cpu()\n",
    "        img = img * 255\n",
    "        img = img.int().permute(1, 2, 0).numpy()\n",
    "        img = sharpen(img)\n",
    "        axs[1].imshow(img)\n",
    "        axs[1].axis('off')\n",
    "\n",
    "        img = true_img[0].cpu()\n",
    "        img = img.int().permute(1, 2, 0).detach().numpy()\n",
    "        axs[2].imshow(img)\n",
    "        axs[2].axis('off')\n",
    "        return\n",
    "\n",
    "    fig, axs = plt.subplots(num, 3, figsize=(9, 3 * num))\n",
    "\n",
    "    for i in range(num):\n",
    "        img = in_imgs[i].cpu()\n",
    "        img = img * 255\n",
    "        img = img.int().permute(1, 2, 0).numpy()\n",
    "        axs[i, 0].imshow(img)\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "    for i in range(num):\n",
    "        img = pred_img[i].cpu()\n",
    "        img = img * 255\n",
    "        img = img.int().permute(1, 2, 0).numpy()\n",
    "        img = sharpen(img)\n",
    "        axs[i, 1].imshow(img)\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "    for i in range(num):\n",
    "        img = true_img[i].cpu()\n",
    "        img = img * 255\n",
    "        img = img.int().permute(1, 2, 0).detach().numpy()\n",
    "        axs[i, 2].imshow(img)\n",
    "        axs[i, 2].axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 1232,
     "status": "ok",
     "timestamp": 1736616162757,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "lPQNAENwU18O"
   },
   "outputs": [],
   "source": [
    "def training_phase(model_path='',\n",
    "                   use_pretrain=True,\n",
    "                   device='cuda'):\n",
    "    if use_pretrain:\n",
    "        print('Using pre-trained model----')\n",
    "        net = UNet().to(device)\n",
    "        net.load_state_dict(torch.load(model_path, weights_only=True, map_location=torch.device(device)))\n",
    "        net.eval()\n",
    "    else:\n",
    "        print('Start training new model----')\n",
    "        net = UNet().to(device)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "        loss_fn = nn.MSELoss().to(device)\n",
    "        ssim = SSIM().to(device)\n",
    "\n",
    "        loss_, ssim_capture = training(net,\n",
    "                                       train_loader,\n",
    "                                       optimizer,\n",
    "                                       loss_fn,\n",
    "                                       ssim)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736615942058,
     "user": {
      "displayName": "Duy Quang",
      "userId": "08397240359579863284"
     },
     "user_tz": -420
    },
    "id": "0aQ9cgnVV_ef"
   },
   "outputs": [],
   "source": [
    "def test_on_single_image(net, img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_torch = torch.from_numpy(np.asarray(img, dtype=np.uint8)).permute(2, 0, 1)\n",
    "\n",
    "    masker = MaskMaker(img_torch.shape[1:]).forward()\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        mask = torch.from_numpy(masker)\n",
    "        img_ = img_torch * mask.unsqueeze(0)\n",
    "        img_ = img_ / 255.0\n",
    "\n",
    "        pred = net(img_.unsqueeze(0).to(device))\n",
    "        plot_result(img_.unsqueeze(0), pred, img_torch.unsqueeze(0))\n",
    "\n",
    "def test_on_many_image(net, num_of_batches, testloader):\n",
    "\n",
    "    maks = MaskMaker((IM_SIZE, IM_SIZE))\n",
    "    with torch.inference_mode():\n",
    "        net.eval()\n",
    "        for batch_idx, (images, _) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            ip = make_input(images).to(device)\n",
    "            y_pred = net(ip)\n",
    "\n",
    "            plot_result(ip, y_pred, images)\n",
    "            i += 1\n",
    "            if i == num_of_batches:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aELi3FyUXDZX"
   },
   "outputs": [],
   "source": [
    "net = training_phase(model_path='/Models/checkpoint.pth', use_pretrain=True, device=device)\n",
    "test_on_single_image(net, '/images/test_image1.jpg')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
